{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing and Data Augmentation\n",
    "\n",
    "1) The .pkl files containing dataframes of all participants are read.<br>\n",
    "\n",
    "2) The finger and phalanx touches are obtained through a customized blob-detection algorithm written using Open CV.<br>\n",
    "\n",
    "3) The detected blobs are filtered using a specific threshold and are appended to same dataframe.<br> \n",
    "\n",
    "4) Data augmentations are also performed on the obtained blobs to increase the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blob_detection(cap_matrix):\n",
    "    '''\n",
    "    performs blob detection over the obtained capactive matrix and returns the exteme left and right positions of the blob\n",
    "    '''\n",
    "    cap_matrix[cap_matrix < 0] = 0  # Negative pixel values are set to 0.\n",
    "\n",
    "    image = np.array(abs(cap_matrix), dtype=np.uint8, copy=True)\n",
    "\n",
    "    # Pixels below this threshold considered as noise.\n",
    "    threshold = 30\n",
    "    ret, threshold = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours will return contours from Threshold image.\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If there is no contours return null coordinates.\n",
    "    if not contours:\n",
    "        rec_pts = [(0, 0), (0, 0)]\n",
    "    \n",
    "    else:\n",
    "        max_cnt = max(contours, key=cv2.contourArea)[:, 0]  # Determines maximum area contour.\n",
    "        minimum_x, maximum_x = min(max_cnt[:, 0]), max(max_cnt[:, 0])\n",
    "        minimum_y, maximum_y = min(max_cnt[:, 1]), max(max_cnt[:, 1])\n",
    "        rec_points = [(minimum_x, minimum_y), (maximum_x, maximum_y)]\n",
    "    \n",
    "    return rec_points\n",
    "\n",
    "# alternate method \n",
    "#     else:\n",
    "#         c = max(contours, key=cv2.contourArea)  # Determines maximum area contour.\n",
    "\n",
    "#         # determine the most extreme points along the contour\n",
    "#         extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "#         extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "#         extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "#         extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "#         alist = [extLeft, extRight, extTop, extBot]\n",
    "#         temp = tuple(map(sorted, zip(*alist)))\n",
    "#         min_x, max_x, min_y, max_y = temp[0][0], temp[0][-1], temp[1][0], temp[1][-1]\n",
    "#         # print(min_x, max_x, min_y, max_y)\n",
    "\n",
    "#         extreme_left = (min_x, min_y)\n",
    "#         extreme_right = (max_x, max_y)\n",
    "\n",
    "#         rec_pts = [extreme_left, extreme_right]\n",
    "\n",
    "#     return rec_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(df=None, participant_no=None):\n",
    "    '''\n",
    "    perform data augmentation by flipping the blobs left right and also up and down to make the dataset 4x large\n",
    "    '''\n",
    "    df_ud = df.copy(deep=True)\n",
    "\n",
    "    for i in range(df_ud.shape[0]):\n",
    "        df_ud.at[i, 'Cropped_Matrix'] = np.flipud(df.Cropped_Matrix[i])\n",
    "\n",
    "    df_original_axes = pd.concat([df, df_ud], ignore_index=True)\n",
    "\n",
    "    df_lr = df_original_axes.copy(deep=True)\n",
    "\n",
    "    for i in range(df_original_axes.shape[0]):\n",
    "        df_lr.at[i, 'Cropped_Matrix'] = np.fliplr(df_original_axes.Cropped_Matrix[i])\n",
    "\n",
    "    df_final = pd.concat([df_original_axes, df_lr], ignore_index=True)\n",
    "    print('Writing augmented data for Participant ' + str(participant_no), 'length', len(df_final))\n",
    "\n",
    "    aug_data_save_path = '/home/rahul/Documents/phalanx_detection/pre_processed_aug/'\n",
    "    if not os.path.exists(aug_data_save_path):\n",
    "        os.makedirs(aug_data_save_path)\n",
    "\n",
    "    # Save augmented data file for individual participant.\n",
    "    df_final.to_pickle(os.path.join(aug_data_save_path, 'Participant_' + str(participant_no) + '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from Participant 1.\n",
      "Number of noisy images deleted are -  8971\n",
      "Writing preprocessed data for Participant 1 length 7948\n",
      "Writing augmented data for Participant 1 length 31792\n",
      "Reading data from Participant 2.\n",
      "Number of noisy images deleted are -  20045\n",
      "Writing preprocessed data for Participant 2 length 10675\n",
      "Writing augmented data for Participant 2 length 42700\n",
      "Reading data from Participant 3.\n",
      "Number of noisy images deleted are -  29604\n",
      "Writing preprocessed data for Participant 3 length 9383\n",
      "Writing augmented data for Participant 3 length 37532\n",
      "Reading data from Participant 4.\n",
      "Number of noisy images deleted are -  42254\n",
      "Writing preprocessed data for Participant 4 length 11724\n",
      "Writing augmented data for Participant 4 length 46896\n",
      "Reading data from Participant 5.\n",
      "Number of noisy images deleted are -  57011\n",
      "Writing preprocessed data for Participant 5 length 13483\n",
      "Writing augmented data for Participant 5 length 53932\n",
      "Reading data from Participant 6.\n",
      "Number of noisy images deleted are -  72892\n",
      "Writing preprocessed data for Participant 6 length 16574\n",
      "Writing augmented data for Participant 6 length 66296\n",
      "Reading data from Participant 7.\n",
      "Number of noisy images deleted are -  91509\n",
      "Writing preprocessed data for Participant 7 length 16708\n",
      "Writing augmented data for Participant 7 length 66832\n",
      "Reading data from Participant 8.\n",
      "Number of noisy images deleted are -  103060\n",
      "Writing preprocessed data for Participant 8 length 12038\n",
      "Writing augmented data for Participant 8 length 48152\n",
      "Reading data from Participant 9.\n",
      "Number of noisy images deleted are -  115878\n",
      "Writing preprocessed data for Participant 9 length 13084\n",
      "Writing augmented data for Participant 9 length 52336\n",
      "Reading data from Participant 10.\n",
      "Number of noisy images deleted are -  129572\n",
      "Writing preprocessed data for Participant 10 length 11866\n",
      "Writing augmented data for Participant 10 length 47464\n",
      "Reading data from Participant 11.\n",
      "Number of noisy images deleted are -  141190\n",
      "Writing preprocessed data for Participant 11 length 12058\n",
      "Writing augmented data for Participant 11 length 48232\n",
      "Reading data from Participant 12.\n",
      "Number of noisy images deleted are -  151092\n",
      "Writing preprocessed data for Participant 12 length 11408\n",
      "Writing augmented data for Participant 12 length 45632\n",
      "Reading data from Participant 13.\n",
      "Number of noisy images deleted are -  163209\n",
      "Writing preprocessed data for Participant 13 length 13212\n",
      "Writing augmented data for Participant 13 length 52848\n",
      "Reading data from Participant 14.\n",
      "Number of noisy images deleted are -  176001\n",
      "Writing preprocessed data for Participant 14 length 12085\n",
      "Writing augmented data for Participant 14 length 48340\n",
      "Reading data from Participant 15.\n",
      "Number of noisy images deleted are -  189396\n",
      "Writing preprocessed data for Participant 15 length 13670\n",
      "Writing augmented data for Participant 15 length 54680\n",
      "Reading data from Participant 16.\n",
      "Number of noisy images deleted are -  206008\n",
      "Writing preprocessed data for Participant 16 length 14880\n",
      "Writing augmented data for Participant 16 length 59520\n",
      "Reading data from Participant 17.\n",
      "Number of noisy images deleted are -  220609\n",
      "Writing preprocessed data for Participant 17 length 13087\n",
      "Writing augmented data for Participant 17 length 52348\n",
      "Reading data from Participant 18.\n",
      "Number of noisy images deleted are -  233377\n",
      "Writing preprocessed data for Participant 18 length 12782\n",
      "Writing augmented data for Participant 18 length 51128\n",
      "Reading data from Participant 19.\n",
      "Number of noisy images deleted are -  250050\n",
      "Writing preprocessed data for Participant 19 length 12997\n",
      "Writing augmented data for Participant 19 length 51988\n",
      "Reading data from Participant 20.\n",
      "Number of noisy images deleted are -  260837\n",
      "Writing preprocessed data for Participant 20 length 9180\n",
      "Writing augmented data for Participant 20 length 36720\n",
      "Reading data from Participant 21.\n",
      "Number of noisy images deleted are -  273349\n",
      "Writing preprocessed data for Participant 21 length 13175\n",
      "Writing augmented data for Participant 21 length 52700\n",
      "Reading data from Participant 22.\n",
      "Number of noisy images deleted are -  284737\n",
      "Writing preprocessed data for Participant 22 length 12029\n",
      "Writing augmented data for Participant 22 length 48116\n",
      "Reading data from Participant 23.\n",
      "Number of noisy images deleted are -  295144\n",
      "Writing preprocessed data for Participant 23 length 10350\n",
      "Writing augmented data for Participant 23 length 41400\n",
      "Reading data from Participant 24.\n",
      "Number of noisy images deleted are -  306816\n",
      "Writing preprocessed data for Participant 24 length 11706\n",
      "Writing augmented data for Participant 24 length 46824\n",
      "Reading data from Participant 25.\n",
      "Number of noisy images deleted are -  316437\n",
      "Writing preprocessed data for Participant 25 length 12414\n",
      "Writing augmented data for Participant 25 length 49656\n",
      "CPU times: user 24min 5s, sys: 2.28 s, total: 24min 7s\n",
      "Wall time: 24min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Read data files of all participants for Pre-processing.\n",
    "dropped_images = 0\n",
    "\n",
    "for participant_no in range(1, 26):\n",
    "    \n",
    "    DATA_PATH = '/home/rahul/Documents/phalanx_detection/pickle_data/Participant_' + str(participant_no) + '.pkl'\n",
    "    print('Reading data from Participant ' + str(participant_no) + '.')\n",
    "    \n",
    "    data_frame = pd.read_pickle(DATA_PATH)\n",
    "    data_frame['Cropped_Matrix'] = [[0]] * len(data_frame)\n",
    "    \n",
    "    for j, matrix in enumerate(data_frame.Matrix):\n",
    "        \n",
    "        cap_matrix = np.reshape(matrix, (27, 15))\n",
    "        rec_pts = blob_detection(cap_matrix)  # Run blob detection on reshaped capacitive matrix.\n",
    "\n",
    "        # Cropping capacitive matrix with blob coordinates with offset of 1 extra row and column.\n",
    "        crop_matrix = cap_matrix[rec_pts[0][1] - 1:rec_pts[1][1] + 1, rec_pts[0][0] - 1:rec_pts[1][0] + 1]\n",
    "        min_area = crop_matrix.shape[0] * crop_matrix.shape[1]\n",
    "        \n",
    "        if min_area > 5:  # If area of pixels is greater than 5 then save in dataframe or drop it as noise.\n",
    "            data_frame.at[j, 'Cropped_Matrix'] = crop_matrix\n",
    "        else:\n",
    "            data_frame.drop(j, inplace=True)\n",
    "            dropped_images += 1  # will keep track of deleted images.\n",
    "\n",
    "    print(\"Number of noisy images deleted are - \", dropped_images)\n",
    "    data_frame = data_frame.reset_index()\n",
    "    pickle_data_save_path = '/home/rahul/Documents/phalanx_detection/pre_processed/'\n",
    "    \n",
    "    if not os.path.exists(pickle_data_save_path):\n",
    "        os.makedirs(pickle_data_save_path)\n",
    "\n",
    "    # Store individual participant's pre processed data as pickle before augmentation.\n",
    "    data_frame.to_pickle(os.path.join(pickle_data_save_path, 'Participant_' + str(participant_no) + '.pkl'))\n",
    "    print('Writing preprocessed data for Participant ' + str(participant_no), 'length', len(data_frame))\n",
    "\n",
    "    # Before running augmentation on data set, drop the following columns which are not necessary for training set.\n",
    "    data_frame_compact = data_frame.drop(['Handedness', 'Finger', 'index', 'Timestamp', 'Matrix'], axis=1)\n",
    "    data_augmentation(data_frame_compact, participant_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
